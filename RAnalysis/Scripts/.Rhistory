design = ~ Temperature+OA+Salinity)
# build the metadata matrix ::::::::::::::::::::::::::::
d18.metadata     <- d18.exp_data %>%
dplyr::select(c('SapleName_readmatrix', 'Temperature', 'OA', 'Salinity')) %>% # coondense dataset to build target matrix
dplyr::rename("Sample.Name" = "SapleName_readmatrix") %>%
dplyr::mutate(All_Treatment = paste(Temperature, OA, Salinity, sep = '.'))
d18.metadata     <- data.frame(d18.metadata[,-1], row.names=d18.metadata[,1]) # move Sample.Name column as row names
d18.metadata.mtx <- as.matrix(d18.metadata, row.names="Oyster.ID") # create matrix
# check for 'TRUE' in each - check before proceeding  design
d18.metadata.mtx <- d18.metadata.mtx[match(colnames(d18.counts_matrix),rownames(d18.metadata.mtx)), ]
# build dds ::::::::::::::::::::::::::::::::::::::::::::
# FULL MODEL
dds.d18 <- DESeqDataSetFromMatrix(countData = d18.counts_matrix,
colData = d18.metadata.mtx,
design = ~ Temperature+
OA+
Salinity+
Temperature:OA+
Temperature:Salinity+
OA:Salinity)
# GROUP MDOEL
dds.d18.group <- DESeqDataSetFromMatrix(countData = d18.counts_matrix,
colData = d18.metadata.mtx,
design = ~ All_Treatment-1)
# DAY 2 PLOT THE (1) READS PER SAMPLE (2) READS PER GENE - FOR EACH DDS
d2.nsamples        <- ncol(counts(dds.d2)) # Number of samples - for the plot label
d2.rps             <- qplot(colSums(counts(dds.d2))) +# reads of reads per sample
labs(x = "Mapped reads per sample", y = "Number of samples",
title = "Day 2 (Larva): Mapped reads per sample") +
geom_label(aes(x = 12e5, y = 1, label = paste(d2.nsamples, "samples")))
d2.ngenes          <- nrow(counts(dds.d2)) # Number of genes
d2.ngenes_min      <- min(rowSums(counts(dds.d2))) #  minimum reads
d2.ngenes_mean.min <- min(rowMeans2(counts(dds.d2))) # minimum row mean
d2.ngenes_max      <- max(rowSums(counts(dds.d2))) #  maximum reads
d2.rpg             <- qplot(log10(rowSums(counts(dds.d2))), bins = 16) + # number of reads per gene
labs(x = "log10(Mapped reads per gene)", y = "Number of genes",
title = "Day 2 (Larva): Mapped reads per gene") +
geom_label(aes(x = 4, y = 3000, label = paste(d2.ngenes, "total genes"))) +
geom_label(aes(x = 4, y = 2700, label = paste("max count =", d2.ngenes_max))) +
geom_label(aes(x = 4, y = 2400, label = paste("min count =", d2.ngenes_min))) +
geom_label(aes(x = 4, y = 2100, label = paste("min mean =", d2.ngenes_mean.min))) +
expand_limits(y=c(NA, 3250))
d2.countfig        <- plot_grid(d2.rps, d2.rpg)
d2.rpg             <- qplot(log10(rowSums(counts(dds.d2))), bins = 16) + # number of reads per gene
labs(x = "log10(Mapped reads per gene)", y = "Number of genes",
title = "Day 2 (Larva): Mapped reads per gene") +
geom_label(aes(x = 4, y = 3000, label = paste(d2.ngenes, "total genes"))) +
geom_label(aes(x = 4, y = 2700, label = paste("max count =", d2.ngenes_max))) +
geom_label(aes(x = 4, y = 2400, label = paste("min count =", d2.ngenes_min))) +
geom_label(aes(x = 4, y = 2100, label = paste("min mean =", d2.ngenes_mean.min))) +
expand_limits(y=c(NA, 3250))
d2.nsamples        <- ncol(counts(dds.d2)) # Number of samples - for the plot label
d2.rps             <- qplot(colSums(counts(dds.d2))) +# reads of reads per sample
labs(x = "Mapped reads per sample", y = "Number of samples",
title = "Day 2 (Larva): Mapped reads per sample") +
geom_label(aes(x = 12e5, y = 1, label = paste(d2.nsamples, "samples")))
d2.ngenes          <- nrow(counts(dds.d2)) # Number of genes
d2.ngenes_min      <- min(rowSums(counts(dds.d2))) #  minimum reads
d2.ngenes_mean.min <- min(rowMeans2(counts(dds.d2))) # minimum row mean
d2.ngenes_max      <- max(rowSums(counts(dds.d2))) #  maximum reads
d2.rpg             <- qplot(log10(rowSums(counts(dds.d2))), bins = 16) + # number of reads per gene
labs(x = "log10(Mapped reads per gene)", y = "Number of genes",
title = "Day 2 (Larva): Mapped reads per gene") +
geom_label(aes(x = 4, y = 3000, label = paste(d2.ngenes, "total genes"))) +
geom_label(aes(x = 4, y = 2700, label = paste("max count =", d2.ngenes_max))) +
geom_label(aes(x = 4, y = 2400, label = paste("min count =", d2.ngenes_min))) +
geom_label(aes(x = 4, y = 2100, label = paste("min mean =", d2.ngenes_mean.min))) +
expand_limits(y=c(NA, 3250))
d2.countfig        <- plot_grid(d2.rps, d2.rpg)
library(dplyr)
library(GenomicFeatures)
library(data.table)
library(calibrate)
# load libraries - notes show the install command needed to install (pre installed)
install.packages("calibrate")
library(calibrate)
library(data.table)
# Plotting
library(ggplot2)
library(cowplot)
library(pheatmap)
library(gplots)
library(RColorBrewer)
library(pcaExplorer)
d2.nsamples        <- ncol(counts(dds.d2)) # Number of samples - for the plot label
d2.rps             <- qplot(colSums(counts(dds.d2))) +# reads of reads per sample
labs(x = "Mapped reads per sample", y = "Number of samples",
title = "Day 2 (Larva): Mapped reads per sample") +
geom_label(aes(x = 12e5, y = 1, label = paste(d2.nsamples, "samples")))
d2.ngenes          <- nrow(counts(dds.d2)) # Number of genes
d2.ngenes_min      <- min(rowSums(counts(dds.d2))) #  minimum reads
d2.ngenes_mean.min <- min(rowMeans2(counts(dds.d2))) # minimum row mean
d2.ngenes_max      <- max(rowSums(counts(dds.d2))) #  maximum reads
d2.rpg             <- qplot(log10(rowSums(counts(dds.d2))), bins = 16) + # number of reads per gene
labs(x = "log10(Mapped reads per gene)", y = "Number of genes",
title = "Day 2 (Larva): Mapped reads per gene") +
geom_label(aes(x = 4, y = 3000, label = paste(d2.ngenes, "total genes"))) +
geom_label(aes(x = 4, y = 2700, label = paste("max count =", d2.ngenes_max))) +
geom_label(aes(x = 4, y = 2400, label = paste("min count =", d2.ngenes_min))) +
geom_label(aes(x = 4, y = 2100, label = paste("min mean =", d2.ngenes_mean.min))) +
expand_limits(y=c(NA, 3250))
d2.countfig        <- plot_grid(d2.rps, d2.rpg)
d18.nsamples        <- ncol(counts(dds.d18.group)) # Number of samples - for the plot label
d18.rps             <- qplot(colSums(counts(dds.d18.group))) +# reads of reads per sample
labs(x = "Mapped reads per sample", y = "Number of samples",
title = "Day 18 (Spat): Mapped reads per sample") +
geom_label(aes(x = 12e5, y = 1, label = paste(d18.nsamples, "samples")))
d18.ngenes          <- nrow(counts(dds.d18.group)) # Number of genes
d18.ngenes_min      <- min(rowSums(counts(dds.d18.group))) #  minimum reads
d18.ngenes_mean.min <- min(rowMeans2(counts(dds.d18.group))) # minimum row mean
d18.ngenes_max      <- max(rowSums(counts(dds.d18.group))) #  maximum reads
d18.rpg             <- qplot(log10(rowSums(counts(dds.d18.group))), bins = 16) + # number of reads per gene
labs(x = "log10(Mapped reads per gene)", y = "Number of genes",
title = "Day 18 (Spat): Mapped reads per gene") +
geom_label(aes(x = 4, y = 3000, label = paste(d18.ngenes, "total genes"))) +
geom_label(aes(x = 4, y = 2700, label = paste("max count =", d18.ngenes_max))) +
geom_label(aes(x = 4, y = 2400, label = paste("min count =", d18.ngenes_min))) +
geom_label(aes(x = 4, y = 2100, label = paste("min mean =", d18.ngenes_mean.min))) +
expand_limits(y=c(NA, 3250))
d18.countfig
d18.countfig        <- plot_grid(d18.rps, d18.rpg)
d18.nsamples        <- ncol(counts(dds.d18.group)) # Number of samples - for the plot label
d18.rps             <- qplot(colSums(counts(dds.d18.group))) +# reads of reads per sample
labs(x = "Mapped reads per sample", y = "Number of samples",
title = "Day 18 (Spat): Mapped reads per sample") +
geom_label(aes(x = 12e5, y = 1, label = paste(d18.nsamples, "samples")))
d18.ngenes          <- nrow(counts(dds.d18.group)) # Number of genes
d18.ngenes_min      <- min(rowSums(counts(dds.d18.group))) #  minimum reads
d18.ngenes_mean.min <- min(rowMeans2(counts(dds.d18.group))) # minimum row mean
d18.ngenes_max      <- max(rowSums(counts(dds.d18.group))) #  maximum reads
d18.rpg             <- qplot(log10(rowSums(counts(dds.d18.group))), bins = 16) + # number of reads per gene
labs(x = "log10(Mapped reads per gene)", y = "Number of genes",
title = "Day 18 (Spat): Mapped reads per gene") +
geom_label(aes(x = 4, y = 3000, label = paste(d18.ngenes, "total genes"))) +
geom_label(aes(x = 4, y = 2700, label = paste("max count =", d18.ngenes_max))) +
geom_label(aes(x = 4, y = 2400, label = paste("min count =", d18.ngenes_min))) +
geom_label(aes(x = 4, y = 2100, label = paste("min mean =", d18.ngenes_mean.min))) +
expand_limits(y=c(NA, 3250))
d18.countfig        <- plot_grid(d18.rps, d18.rpg)
plot_grid(d2.countfig, d18.countfig)
# RUN DESEQ2 model - view all the pariwise comparisons
dds.d2        <- DESeq(dds.d2) #  full model            wait for this to complete....
dds.d2.group  <- DESeq(dds.d2.group) # group model      wait for this to complete....
dds.d18.group <- DESeq(dds.d18.group) # group model       wait for this to complete....
# Data transformations for heatmap and PCA visuals :::::::
# rlog - regularized log transformation of origin count data to log2 scale - fit for each sample and dist. of coefficients in the data
rlog.d2<- rlogTransformation(dds.d2) # rlog transform (regularized log)
rlog.d2
rlog.d2[,1:4]
iris
as.data.frame(rlog.d2)
rlog.d2
assay(rlog.d2[res.index,])
assay(rlog.d2)
head(assay(rlog.d2))
rlog.d2
head(assay(rlog.d2))[1]
head(assay(rlog.d2))[,1]
head(assay(rlog.d2))[1,]
head(assay(rlog.d2))[,1]
head(assay(rlog.d2))[,c(1:2)]
(ncol(assay(rlog.d2)))
head(assay(rlog.d2))[,c(1:(ncol(assay(rlog.d2))))]
dat <- assay(rlog.d2)[,c(1:(ncol(assay(rlog.d2))))]
dat <- as.data.frame(assay(rlog.d2)[,c(1:(ncol(assay(rlog.d2))))])
head(dat)
pca = prcomp(dat)
dat %>% remove_rownames %>% column_to_rownames(var="Sample.ID")
library(tidyverse)
dat %>% remove_rownames %>% column_to_rownames(var="Sample.ID")
samp.with.rownames <- data.frame(dat[,-1], row.names=dat[,1])
samp.with.rownames
samp.with.rownames <- as.data.frame(t(dat))
samp.with.rownames
samp.with.rownames <- as.data.frame(t(dat)) %>% tibble::rownames_to_column("Sample.ID")
samp.with.rownames
assay(rlog.d2)
samp.with.rownames
d2.exp_data
d18.exp_data
d2.exp_data_rename
d2.exp_data
d2.exp_data_rename <- d2.exp_data %>% rename('Sample.ID' = 'SapleName_readmatrix')
d2.exp_data_rename <- d2.exp_data %>% dplyr::rename('Sample.ID' = 'SapleName_readmatrix')
d2.exp_data_rename
samp.with.rownames <- as.data.frame(t(dat)) %>%
tibble::rownames_to_column("Sample.ID") %>%
merge(samp.with.rownames, d2.exp_data_rename)
merge(samp.with.rownames, d2.exp_data_rename)
ncol(samp.with.rownames)
samp.with.rownamesMERGED <- merge(samp.with.rownames, d2.exp_data_rename)
ncol(samp.with.rownamesMERGED)
ncol(samp.with.rownames)
pca = prcomp(samp.with.rownamesMERGED[,c(2:4821)])
ggbiplot(pca,groups = samp.with.rownamesMERGED$Salinity,ellipse = T,ellipse.prob = .95)
iris
d2.exp_data_rename
samp.with.rownames
iris
dat <- as.data.frame(assay(rlog.d2)[,c(1:(ncol(assay(rlog.d2))))])
dat
assay(rlog.d2$All_Treatment
assay(rlog.d2$All_Treatment)
assay(rlog.d2$All_Treatment)
# LOAD PACKAGES :::::::::::::::::::::::::::::::::::::::::::::::::::::::
library(dplyr)
library(ggplot2)
library(forcats)
library(lme4)
library(lmerTest)
library(see)
library(performance)
library(car)
library(kableExtra)
library(pander)
library(data.table)
library(stringr)
library(latex2exp)
library(Rmisc)
library(devtools)
library(ggpubr)
library(hrbrthemes)
# SET WORKING DIRECTORY :::::::::::::::::::::::::::::::::::::::::::::::
setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # personal computer
# setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # Work computer
# LOAD DATA :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
resp.data              <- read.csv(file="Output/Respiration/Cumulative_resp_alpha0.4_15sectrunc1hour.csv", header=T) %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt') # read the calculate raw rates from 'resp_LoLin' script - contains the calculated rate (not normalized for blanks) for each sensor-channel
start.end_resp.data    <- read.csv(file="Output/Respiration/Cumulative_resp_start_end.csv", header=T, sep = "") %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt') # read the start and end simplified resp data
resp.ref               <- read.csv(file="Data/Respiration/Reference_master.csv", header=T) %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt')
lengths                <- read.csv(file="Data/Respiration/Lengths_Condition_resp_clearance.csv", header=T)
lengths_spat           <- read.csv(file="Data/Respiration/Lengths_larvae_spat_resp.csv", header=T)
lengths_spat
resp.data
nrow(resp.data) == nrow(start.end_resp.data) # MUST be TRUE
resp_all_raw <- merge(resp.data, start.end_resp.data)
# merge the exp_metadata with the resp.data
resp.ref_length_merged                 <- merge(resp.ref, lengths) # all TRUE allows us to keep the blanks
resp.data_merged                       <- merge(resp_all_raw, resp.ref_length_merged) %>% # out master file moving forward....
dplyr::mutate(filetype = str_sub(Filename, -3,-1)) %>%
dplyr::mutate(filetype = factor(ifelse(filetype == "csv", "SDR_data", "LoLigo_data"))) %>%
dplyr::mutate(Date_formatted =  gsub("-", "", substr( (strptime(Date, "%m/%d/%Y")), 1,10)) ) %>%
dplyr::arrange(Date_formatted,Run, Channel, .by_group = TRUE)
kable(head(resp.data_merged))
View(resp.data_merged)
lengths
lengths_spat
lengths
resp.ref_length_merged
lengths_spat
nrow(resp.data) == nrow(start.end_resp.data) # MUST be TRUE
nrow(start.end_resp.data)
nrow(resp.data)
lengths_spat
lengths_spat %>% dplyr::group_by(Date,Run,Plate,Channel)
lengths_spat %>% dplyr::group_by(Date,Run,Plate,Channel) %>% dplyr::summarise(Length = mean(Length))
head(lengths_spat) # take a look at it here
lengths_spat_MEAN <- as.data.frame(lengths_spat %>%
dplyr::group_by(Date,Run,Plate,Channel) %>%
dplyr::summarise(Length = mean(Length))) # group and summarise as a mean
lengths_spat_MEAN
rbind(lengths, lengths_spat_MEAN)
lengths_spat_MEAN
lengths
lengths_spat_MEAN <- as.data.frame(lengths_spat %>%
dplyr::group_by(Date,Run,Plate,Channel) %>%
dplyr::summarise(Length_um = mean(Length))) # group and summarise as a mean
rbind(lengths, lengths_spat_MEAN)
merge(lengths, lengths_spat_MEAN)
rbind.fill(lengths, lengths_spat_MEAN)
lenghts_master <- rbind.fill(lengths, lengths_spat_MEAN) # now we can bind, use rbind.fill to adhere including NAs for missing columns
# lengths_spat contains early development resp runs
# as multiple individuals per well (in some cases!)
# whereas 'lengths' is for juvenile-adult stage scallops each as one length for each resp value
# thus, we need to summarise as a mean for the 'lengths_spat' file before merging with the other file
head(lengths)
# merge the exp_metadata with the resp.data
resp.ref_length_merged                 <- merge(resp.ref, lengths) # all TRUE allows us to keep the blanks
resp.data_merged                       <- merge(resp.data, resp.ref_length_merged) %>% # out master file moving forward....
dplyr::mutate(filetype = str_sub(Filename, -3,-1)) %>%
dplyr::mutate(filetype = factor(ifelse(filetype == "csv", "SDR_data", "LoLigo_data"))) %>%
dplyr::mutate(Date_formatted =  gsub("-", "", substr( (strptime(Date, "%m/%d/%Y")), 1,10)) ) %>%
dplyr::arrange(Date_formatted,Run, Channel, .by_group = TRUE)
View(resp.data_merged)
head(lengths_spat) # take a look at it here, you see muliple entries for a single well for the larvae/spat resp runs
resp.ref_length_merged
resp.ref
merge(resp.ref, lengths)
# merge the exp_metadata with the resp.data
resp.ref_length_merged                 <- merge(resp.ref, lenghts_master) # all TRUE allows us to keep the blanks
nrow(lenghts_master)
nrow(resp.ref_length_merged)
nrow(resp.ref_length_merged)
lenghts_master
resp.ref
lenghts_master
resp.ref
# LOAD PACKAGES :::::::::::::::::::::::::::::::::::::::::::::::::::::::
library(dplyr)
library(ggplot2)
library(forcats)
library(lme4)
library(lmerTest)
library(see)
library(performance)
library(car)
library(kableExtra)
library(pander)
library(data.table)
library(stringr)
library(latex2exp)
library(Rmisc)
library(devtools)
library(ggpubr)
library(hrbrthemes)
# SET WORKING DIRECTORY :::::::::::::::::::::::::::::::::::::::::::::::
setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # personal computer
# setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # Work computer
# LOAD DATA :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
resp.data              <- read.csv(file="Output/Respiration/Cumulative_resp_alpha0.4_15sectrunc1hour.csv", header=T) %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt') # read the calculate raw rates from 'resp_LoLin' script - contains the calculated rate (not normalized for blanks) for each sensor-channel
start.end_resp.data    <- read.csv(file="Output/Respiration/Cumulative_resp_start_end.csv", header=T, sep = "") %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt') # read the start and end simplified resp data
resp.ref               <- read.csv(file="Data/Respiration/Reference_master.csv", header=T) %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt')
# data to correct for length, dry weight, etc.
lengths_juv_adults     <- read.csv(file="Data/Respiration/Lengths_Condition_resp_clearance.csv", header=T)
lengths_spat           <- read.csv(file="Data/Respiration/Lengths_larvae_spat_resp.csv", header=T)
blanks_means <- merge(blanks_meansLoLin, blanks_meansStartEnd) %>% dplyr::arrange(Date_formatted, Run, pH)
# LOAD PACKAGES :::::::::::::::::::::::::::::::::::::::::::::::::::::::
library(dplyr)
library(ggplot2)
library(forcats)
library(lme4)
library(lmerTest)
library(see)
library(performance)
library(car)
library(kableExtra)
library(pander)
library(data.table)
library(stringr)
library(latex2exp)
library(Rmisc)
library(devtools)
library(ggpubr)
library(hrbrthemes)
# SET WORKING DIRECTORY :::::::::::::::::::::::::::::::::::::::::::::::
setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # personal computer
# setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # Work computer
# LOAD DATA :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
resp.data              <- read.csv(file="Output/Respiration/Cumulative_resp_alpha0.4_15sectrunc1hour.csv", header=T) %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt') # read the calculate raw rates from 'resp_LoLin' script - contains the calculated rate (not normalized for blanks) for each sensor-channel
start.end_resp.data    <- read.csv(file="Output/Respiration/Cumulative_resp_start_end.csv", header=T, sep = "") %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt') # read the start and end simplified resp data
resp.ref               <- read.csv(file="Data/Respiration/Reference_master.csv", header=T) %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt')
# data to correct for length, dry weight, etc.
lengths_juv_adults     <- read.csv(file="Data/Respiration/Lengths_Condition_resp_clearance.csv", header=T)
lengths_spat           <- read.csv(file="Data/Respiration/Lengths_larvae_spat_resp.csv", header=T)
# lengths_spat contains early development resp runs
# as multiple individuals per well (in some cases!)
# whereas 'lengths' is for juvenile-adult stage scallops each as one length for each resp value
# thus, we need to summarise as a mean for the 'lengths_spat' file before merging with the other file
head(lengths_juv_adults) # here are the juveniles and adults - a single length individual for each resp channel
head(lengths_spat) # take a look at it here, you see muliple entries for a single well for the larvae/spat resp runs
lengths_spat_MEAN <- as.data.frame(lengths_spat %>%
dplyr::group_by(Date,Run,Plate,Channel, Chamber_tank,Number,pH) %>%
dplyr::summarise(Length_um = mean(Length))) %>% # group and summarise as a mean
dplyr::select(!Channel)
lenghts_master <- rbind.fill(lengths_juv_adults, lengths_spat_MEAN) # use rbind.fill to merge including NAs for missing columns
# check the data - ensure all data was run
if(nrow(resp.data) == nrow(start.end_resp.data)){ # MUST be TRUE
resp_all_raw <- merge(resp.data, start.end_resp.data)
} else{}
# merge the exp_metadata with the resp.data
resp.ref_length_merged                 <- merge(resp.ref,
lenghts_master) # all TRUE allows us to keep the blanks
resp.data_merged                       <- merge(resp.data, resp.ref_length_merged) %>% # out master file moving forward....
dplyr::mutate(filetype = str_sub(Filename, -3,-1)) %>%
dplyr::mutate(filetype = factor(ifelse(filetype == "csv",
"SDR_data",
"LoLigo_data"))) %>%
dplyr::mutate(Date_formatted =  gsub("-", "", substr( (strptime(Date, "%m/%d/%Y")), 1,10)) ) %>%
dplyr::arrange(Date_formatted,Run, Channel, .by_group = TRUE)
kable(head(resp.data_merged))
View(resp.data_merged)
resp.data_merged[47,c(1:6)]  # 	C1 RR_9.30.21_AM_Plate_2_Run_1.csv # -0.02890813	-0.0608251	-0.0608251 - Lz and Leq call better regression than Lp5resp.data_merged[124,c(1:6)]
resp.data_merged[90,c(1:6)]  #   C5 RR_9.30.21_PM_Plate_2_Run_2.csv	0.029052351	-0.076034441	-0.076034441
resp.data_merged[84,c(1:6)]  # 	C1 RR_9.30.21_PM_Plate_1_Run_2.csv	0.011656487	0.011656487	0.011656487  - ommit this
resp.data_merged[135,c(1:6)]   # 	2/2/2022	CH1	run_1_raw.txt  -0.03291728	-0.02714124	-0.0271412; data change Lpc to -0.0209
resp.data_merged[148,c(1:6)]   # 	2/2/2022	CH2	run_3_raw.txt	-0.004996976	-0.007234043	-0.007234043; data change Lpc to -0.0124
# change according to diagnostics of plots and in Lolin script
resp.data_merged[47,4] <- resp.data_merged[47,5] # 20210930_Plate_2_Run_2_C5_regression - Lz and Leq call better regression than Lpc
resp.data_merged[90,4] <- resp.data_merged[90,5] # 20210930_Plate_2_Run_1_C1_regression - Lz and Leq call better regression than Lpc
resp.data_merged[84,4] <- -0.0296 # 20210930_Plate_1_Run_2_C1_regression - plot shows noise after the 20 minutes mark, we reran this at the end of the LoLin script, insert here!
resp.data_merged[135,4] <- -0.0209
resp.data_merged[148,4] <- -0.0124
# double check if correct
resp.data_merged[47,c(1:6)] # -0.0608251
resp.data_merged[90,c(1:6)] # -0.07603444
resp.data_merged[84,c(1:6)] # -0.0296
resp.data_merged[135,c(1:6)]  # -0.0209
resp.data_merged[148,c(1:6)]  # -0.0124
blanks_total <- data.frame() # start dataframe
blanks.table <- data.frame(matrix(nrow = 1,ncol = 5)) # make a table template
colnames(blanks.table)<-c('Date', 'Channel', 'mean_Lpc', 'mean_Leq' , 'mean_Lz') # names for comuns in the for loop
blanks_all_raw <- data.frame((merge(resp_all_raw, resp.ref)) %>% #data.frame(merge(resp.ref, resp.data, by = c('Date', 'Channel', 'Filename')) %>%
dplyr::mutate(filetype = str_sub(Filename, -3,-1)) %>%
dplyr::mutate(filetype = factor(ifelse(filetype == "csv", "SDR_data", "LoLigo_data"))) %>%
dplyr::filter(Chamber_tank  == 'blank') %>%
#dplyr::filter(Lpc <0) %>%
dplyr::filter(!Date == '9/30/2021' | !Lpc < -0.035) %>% #omits C6 RR_9.30.21_AM_Plate_1_Run_1.csv	8.0	blank - View the Lolin plot, looks noisy and a fast outlier from the others
dplyr::filter(!Date == '10/26/2021'  | !Channel == "CH8" | !Run == "2" ) %>% # omit a bad blank that contained a bad seal, noted on the respiration sampling day during the trial
dplyr::select(c('Date', 'Run', 'Channel','Filename','pH','Lpc', 'Leq', 'Lz', 'Rate_mgO2_hour','filetype')) %>% # ,
dplyr::arrange(Date,pH, .by_group = TRUE))
resp_all_raw <- merge(resp.data, start.end_resp.data)
blanks_total <- data.frame() # start dataframe
blanks.table <- data.frame(matrix(nrow = 1,ncol = 5)) # make a table template
colnames(blanks.table)<-c('Date', 'Channel', 'mean_Lpc', 'mean_Leq' , 'mean_Lz') # names for comuns in the for loop
blanks_all_raw <- data.frame((merge(resp_all_raw, resp.ref)) %>% #data.frame(merge(resp.ref, resp.data, by = c('Date', 'Channel', 'Filename')) %>%
dplyr::mutate(filetype = str_sub(Filename, -3,-1)) %>%
dplyr::mutate(filetype = factor(ifelse(filetype == "csv", "SDR_data", "LoLigo_data"))) %>%
dplyr::filter(Chamber_tank  == 'blank') %>%
#dplyr::filter(Lpc <0) %>%
dplyr::filter(!Date == '9/30/2021' | !Lpc < -0.035) %>% #omits C6 RR_9.30.21_AM_Plate_1_Run_1.csv	8.0	blank - View the Lolin plot, looks noisy and a fast outlier from the others
dplyr::filter(!Date == '10/26/2021'  | !Channel == "CH8" | !Run == "2" ) %>% # omit a bad blank that contained a bad seal, noted on the respiration sampling day during the trial
dplyr::select(c('Date', 'Run', 'Channel','Filename','pH','Lpc', 'Leq', 'Lz', 'Rate_mgO2_hour','filetype')) %>% # ,
dplyr::arrange(Date,pH, .by_group = TRUE))
# kable((blanks_all_raw)[,c(1:3,6,8,12:14)])
# mean blanks for the LoLinR output ('Lpc')
blanks_meansLoLin <- blanks_all_raw %>%
dplyr::group_by(Date, pH, Run, filetype) %>% # grouped by date, pH, and instrument - similar among Runs
dplyr::filter(Lpc <0) %>% # ommit blank calls that d/n represent oxygen consumption
dplyr::summarise(BLANK.mean_Lpc = mean(abs(Lpc)),
#   = sd(abs(Lpc)),
# BLANK.mean_Leq = mean(abs(Leq)),
# BLANK.mean_Lz  = mean(abs(Lz)),
n = n()) %>%
dplyr::mutate(Date_formatted =  gsub("-", "", substr( (strptime(Date, "%m/%d/%Y")), 1,10)) ) %>%
dplyr::arrange(Date_formatted, Run, pH)
# kable(blanks_meansLoLin) # View - notice some of the date/runs combos do not have BOTH treatmentents represented!
dups_LoLin        <- blanks_meansLoLin[c(1, 16,19,20,23,26),] %>% # call the rows that do not have BOTH pH 7.5 and 8.0 represented (due to positive rates, bad data, etc)
dplyr::mutate(pH = ifelse(pH == 8.0, 7.5,  ifelse(pH == 7.5, 8.0, NA))) # do a little conditional call to call the opposite treatment in this dataframe..
blanks_meansLoLin <- rbind(blanks_meansLoLin, dups_LoLin) %>%  dplyr::arrange(Date_formatted, Run, pH)
# mean blanks for the start - to - end values ('Rate_mgO2_hour')
blanks_meansStartEnd <- blanks_all_raw %>%
dplyr::group_by(Date, pH, Run, filetype) %>% # grouped by date, pH, and instrument - similar among Runs
dplyr::filter(!Rate_mgO2_hour < 0) %>% # ommit blank calls that d/n represent oxygen consumption
dplyr::summarise(BLANK.start.end_mean  = mean(Rate_mgO2_hour),
# BLANK.start.end_sd  = sd(Rate_mgO2_hour),
n = n()) %>%
dplyr::mutate(Date_formatted =  gsub("-", "", substr( (strptime(Date, "%m/%d/%Y")), 1,10)) ) %>%
dplyr::arrange(Date_formatted, Run, pH)
# kable(blanks_meansStartEnd) # View - notice some of the date/runs combos do not have BOTH treatmentents represented!
dups_StartEnd          <- blanks_meansStartEnd[c(1, 16,19,28),] %>% # call the rows that do not have BOTH pH 7.5 and 8.0 represented (due to positive rates, bad data, etc)
dplyr::mutate(pH = ifelse(pH == 8.0, 7.5,  ifelse(pH == 7.5, 8.0, NA))) # do a little conditional call to call the opposite treatment dataframe..
blanks_meansStartEnd   <- rbind(blanks_meansStartEnd, dups_StartEnd) %>%  dplyr::arrange(Date_formatted, Run, pH)
blanks_means <- merge(blanks_meansLoLin, blanks_meansStartEnd) %>% dplyr::arrange(Date_formatted, Run, pH)
kable(blanks_means) # View the inserted duplicates for the other treatment on same run/date
Resp.Master <- merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0) %>% # remove values with positive O2 - should be none here, double check by removing the '!' and run partial pipeline (found 9/14/2021	pH 8	LoLigo_data	CH1)
dplyr::mutate(resp_blankStand = (abs(Lpc)) - BLANK.mean_Lpc)  %>%  # Lpc =  Lolin calculated resp (used for SMR actual rates), raw value is negative, take the absolute value and subtract from the mean blank Lpc (already abs value)
dplyr::mutate(start.end_resp_blankStand = Rate_mgO2_hour - BLANK.start.end_mean) # just start and end (simplified rate in mg O2 per hour) for O:N comparisons
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype"))
blanks_means
resp.data_merged
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0)
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0) %>% # remove values with positive O2 - should be none here, double check by removing the '!' and run partial pipeline (found 9/14/2021	pH 8	LoLigo_data	CH1)
dplyr::mutate(resp_blankStand = (abs(Lpc)) - BLANK.mean_Lpc)
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0) %>% # remove values with positive O2 - should be none here, double check by removing the '!' and run partial pipeline (found 9/14/2021	pH 8	LoLigo_data	CH1)
dplyr::mutate(resp_blankStand = (abs(Lpc)) - BLANK.mean_Lpc)  %>%  # Lpc =  Lolin calculated resp (used for SMR actual rates), raw value is negative, take the absolute value and subtract from the mean blank Lpc (already abs value)
dplyr::mutate(start.end_resp_blankStand = Rate_mgO2_hour - BLANK.start.end_mean)
resp.data_merged
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0)
resp.data_merged
Resp.Master <- merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0) %>% # remove values with positive O2 - should be none here, double check by removing the '!' and run partial pipeline (found 9/14/2021	pH 8	LoLigo_data	CH1)
dplyr::mutate(resp_blankStand = (abs(Lpc)) - BLANK.mean_Lpc)
Resp.Master
plot(Resp.Master$start.end_resp_blankStand, Resp.Master$resp_blankStand)
Resp.Master_OM <- Resp.Master[!is.na(Resp.Master$Length_um),] %>% dplyr::filter(!resp_blankStand < 0) %>% # ommit respiration values that are positive
dplyr::mutate(volume = case_when(filetype == "LoLigo_data" & Date == '9/14/2021' ~ 2.2, # small vessels for loligo system - 22 ml vessels
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH1' ~ 68.55323, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH2' ~ 68.85583, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021')                       & Channel == 'CH3' ~ 68.87473, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH4' ~ 68.95481, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH5' ~ 68.57288, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH6' ~ 68.01878, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH7' ~ 68.54551, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH8' ~ 68.53297, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('2/2/2022','3/1/2022') & Channel == 'CH3' ~ 68.87473, # larger custom vessels measured individually... # note ch3 used vessel #9 on and after 2/2/2022
filetype == "SDR_data" ~ 1.7, # 24-well plate - 1700ul
filetype == "SDR_data" & Date %in% ('8/30/2022') ~ 0.8)) %>% # 24-well plate - 80 ul
# true rates calculated using LoLinRscript
dplyr::mutate(resp_mg_L_hr   = ( (abs(resp_blankStand)) *  # currently as just mg O2 per minute
(volume/1000) * # correct Liters - mg per L per min
60) )  %>% # convert rate per minutes to rate per hour
dplyr::mutate(resp_umol_L_hr = (resp_mg_L_hr*1000) / 32) %>% #  convert mg L per hr to umol L hr- first by mg to ug (mg*1000 = ug) and then ug to umol (1 umol = 32 ug -  ug O2 div 32 ug/umol)
# simplified start end rates used to compare O:N ratios
dplyr::mutate(start.end_resp_mg_L_hr   = (start.end_resp_blankStand*(volume/1000)))  %>% # convert rate per minutes to rate per hour
dplyr::mutate(start.end_resp_umol_L_hr = (((start.end_resp_mg_L_hr) * (1000)) / 32) ) %>% #  convert mg L per hr to umol L hr- first by mg to ug (mg*1000 = ug) and then ug to umol (1 umol = 32 ug -  ug O2 div 32 ug/umol)
dplyr::mutate(Age = case_when(Date == '9/14/2021' ~ 50, Date == '9/30/2021' ~ 66, Date == '10/26/2021' ~ 92, Date == '2/2/2022' ~ 190, Date == '3/1/2022' ~ 217)) %>%
dplyr::mutate(Fed_Unfed = case_when(Fed_Unfed == 'F' ~ "High food", is.na(Fed_Unfed) ~ "High food", Fed_Unfed == 'U' ~ "Low food")) %>%
dplyr::mutate(pCO2 = case_when(pH == 8.0 ~ "500 μatm", pH == 7.5 ~ "800 μatm"))
resp.ref
