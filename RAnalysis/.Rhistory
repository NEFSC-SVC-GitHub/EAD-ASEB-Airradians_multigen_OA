library(performance)
library(car)
library(kableExtra)
library(pander)
library(data.table)
library(stringr)
library(latex2exp)
library(Rmisc)
library(devtools)
library(ggpubr)
library(hrbrthemes)
# SET WORKING DIRECTORY :::::::::::::::::::::::::::::::::::::::::::::::
setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # personal computer
# setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # Work computer
# LOAD DATA :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
resp.data              <- read.csv(file="Output/Respiration/Cumulative_resp_alpha0.4_15sectrunc1hour.csv", header=T) %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt') # read the calculate raw rates from 'resp_LoLin' script - contains the calculated rate (not normalized for blanks) for each sensor-channel
start.end_resp.data    <- read.csv(file="Output/Respiration/Cumulative_resp_start_end.csv", header=T, sep = "") %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt') # read the start and end simplified resp data
resp.ref               <- read.csv(file="Data/Respiration/Reference_master.csv", header=T) %>%
dplyr::filter(!Date %in% "9/14/2021" | !Filename %in% 'Run_1_raw.txt')
# data to correct for length, dry weight, etc.
lengths_juv_adults     <- read.csv(file="Data/Respiration/Lengths_Condition_resp_clearance.csv", header=T)
lengths_spat           <- read.csv(file="Data/Respiration/Lengths_larvae_spat_resp.csv", header=T)
# lengths_spat contains early development resp runs
# as multiple individuals per well (in some cases!)
# whereas 'lengths' is for juvenile-adult stage scallops each as one length for each resp value
# thus, we need to summarise as a mean for the 'lengths_spat' file before merging with the other file
head(lengths_juv_adults) # here are the juveniles and adults - a single length individual for each resp channel
head(lengths_spat) # take a look at it here, you see muliple entries for a single well for the larvae/spat resp runs
lengths_spat_MEAN <- as.data.frame(lengths_spat %>%
dplyr::group_by(Date,Run,Plate,Channel, Chamber_tank,Number,pH) %>%
dplyr::summarise(Length_um = mean(Length))) %>% # group and summarise as a mean
dplyr::select(!Channel)
lenghts_master <- rbind.fill(lengths_juv_adults, lengths_spat_MEAN) # use rbind.fill to merge including NAs for missing columns
# check the data - ensure all data was run
if(nrow(resp.data) == nrow(start.end_resp.data)){ # MUST be TRUE
resp_all_raw <- merge(resp.data, start.end_resp.data)
} else{}
# merge the exp_metadata with the resp.data
resp.ref_length_merged                 <- merge(resp.ref,
lenghts_master) # all TRUE allows us to keep the blanks
resp.data_merged                       <- merge(resp.data, resp.ref_length_merged) %>% # out master file moving forward....
dplyr::mutate(filetype = str_sub(Filename, -3,-1)) %>%
dplyr::mutate(filetype = factor(ifelse(filetype == "csv",
"SDR_data",
"LoLigo_data"))) %>%
dplyr::mutate(Date_formatted =  gsub("-", "", substr( (strptime(Date, "%m/%d/%Y")), 1,10)) ) %>%
dplyr::arrange(Date_formatted,Run, Channel, .by_group = TRUE)
kable(head(resp.data_merged))
View(resp.data_merged)
resp.data_merged[47,c(1:6)]  # 	C1 RR_9.30.21_AM_Plate_2_Run_1.csv # -0.02890813	-0.0608251	-0.0608251 - Lz and Leq call better regression than Lp5resp.data_merged[124,c(1:6)]
resp.data_merged[90,c(1:6)]  #   C5 RR_9.30.21_PM_Plate_2_Run_2.csv	0.029052351	-0.076034441	-0.076034441
resp.data_merged[84,c(1:6)]  # 	C1 RR_9.30.21_PM_Plate_1_Run_2.csv	0.011656487	0.011656487	0.011656487  - ommit this
resp.data_merged[135,c(1:6)]   # 	2/2/2022	CH1	run_1_raw.txt  -0.03291728	-0.02714124	-0.0271412; data change Lpc to -0.0209
resp.data_merged[148,c(1:6)]   # 	2/2/2022	CH2	run_3_raw.txt	-0.004996976	-0.007234043	-0.007234043; data change Lpc to -0.0124
# change according to diagnostics of plots and in Lolin script
resp.data_merged[47,4] <- resp.data_merged[47,5] # 20210930_Plate_2_Run_2_C5_regression - Lz and Leq call better regression than Lpc
resp.data_merged[90,4] <- resp.data_merged[90,5] # 20210930_Plate_2_Run_1_C1_regression - Lz and Leq call better regression than Lpc
resp.data_merged[84,4] <- -0.0296 # 20210930_Plate_1_Run_2_C1_regression - plot shows noise after the 20 minutes mark, we reran this at the end of the LoLin script, insert here!
resp.data_merged[135,4] <- -0.0209
resp.data_merged[148,4] <- -0.0124
# double check if correct
resp.data_merged[47,c(1:6)] # -0.0608251
resp.data_merged[90,c(1:6)] # -0.07603444
resp.data_merged[84,c(1:6)] # -0.0296
resp.data_merged[135,c(1:6)]  # -0.0209
resp.data_merged[148,c(1:6)]  # -0.0124
blanks_total <- data.frame() # start dataframe
blanks.table <- data.frame(matrix(nrow = 1,ncol = 5)) # make a table template
colnames(blanks.table)<-c('Date', 'Channel', 'mean_Lpc', 'mean_Leq' , 'mean_Lz') # names for comuns in the for loop
blanks_all_raw <- data.frame((merge(resp_all_raw, resp.ref)) %>% #data.frame(merge(resp.ref, resp.data, by = c('Date', 'Channel', 'Filename')) %>%
dplyr::mutate(filetype = str_sub(Filename, -3,-1)) %>%
dplyr::mutate(filetype = factor(ifelse(filetype == "csv", "SDR_data", "LoLigo_data"))) %>%
dplyr::filter(Chamber_tank  == 'blank') %>%
#dplyr::filter(Lpc <0) %>%
dplyr::filter(!Date == '9/30/2021' | !Lpc < -0.035) %>% #omits C6 RR_9.30.21_AM_Plate_1_Run_1.csv	8.0	blank - View the Lolin plot, looks noisy and a fast outlier from the others
dplyr::filter(!Date == '10/26/2021'  | !Channel == "CH8" | !Run == "2" ) %>% # omit a bad blank that contained a bad seal, noted on the respiration sampling day during the trial
dplyr::select(c('Date', 'Run', 'Channel','Filename','pH','Lpc', 'Leq', 'Lz', 'Rate_mgO2_hour','filetype')) %>% # ,
dplyr::arrange(Date,pH, .by_group = TRUE))
resp_all_raw <- merge(resp.data, start.end_resp.data)
blanks_total <- data.frame() # start dataframe
blanks.table <- data.frame(matrix(nrow = 1,ncol = 5)) # make a table template
colnames(blanks.table)<-c('Date', 'Channel', 'mean_Lpc', 'mean_Leq' , 'mean_Lz') # names for comuns in the for loop
blanks_all_raw <- data.frame((merge(resp_all_raw, resp.ref)) %>% #data.frame(merge(resp.ref, resp.data, by = c('Date', 'Channel', 'Filename')) %>%
dplyr::mutate(filetype = str_sub(Filename, -3,-1)) %>%
dplyr::mutate(filetype = factor(ifelse(filetype == "csv", "SDR_data", "LoLigo_data"))) %>%
dplyr::filter(Chamber_tank  == 'blank') %>%
#dplyr::filter(Lpc <0) %>%
dplyr::filter(!Date == '9/30/2021' | !Lpc < -0.035) %>% #omits C6 RR_9.30.21_AM_Plate_1_Run_1.csv	8.0	blank - View the Lolin plot, looks noisy and a fast outlier from the others
dplyr::filter(!Date == '10/26/2021'  | !Channel == "CH8" | !Run == "2" ) %>% # omit a bad blank that contained a bad seal, noted on the respiration sampling day during the trial
dplyr::select(c('Date', 'Run', 'Channel','Filename','pH','Lpc', 'Leq', 'Lz', 'Rate_mgO2_hour','filetype')) %>% # ,
dplyr::arrange(Date,pH, .by_group = TRUE))
# kable((blanks_all_raw)[,c(1:3,6,8,12:14)])
# mean blanks for the LoLinR output ('Lpc')
blanks_meansLoLin <- blanks_all_raw %>%
dplyr::group_by(Date, pH, Run, filetype) %>% # grouped by date, pH, and instrument - similar among Runs
dplyr::filter(Lpc <0) %>% # ommit blank calls that d/n represent oxygen consumption
dplyr::summarise(BLANK.mean_Lpc = mean(abs(Lpc)),
#   = sd(abs(Lpc)),
# BLANK.mean_Leq = mean(abs(Leq)),
# BLANK.mean_Lz  = mean(abs(Lz)),
n = n()) %>%
dplyr::mutate(Date_formatted =  gsub("-", "", substr( (strptime(Date, "%m/%d/%Y")), 1,10)) ) %>%
dplyr::arrange(Date_formatted, Run, pH)
# kable(blanks_meansLoLin) # View - notice some of the date/runs combos do not have BOTH treatmentents represented!
dups_LoLin        <- blanks_meansLoLin[c(1, 16,19,20,23,26),] %>% # call the rows that do not have BOTH pH 7.5 and 8.0 represented (due to positive rates, bad data, etc)
dplyr::mutate(pH = ifelse(pH == 8.0, 7.5,  ifelse(pH == 7.5, 8.0, NA))) # do a little conditional call to call the opposite treatment in this dataframe..
blanks_meansLoLin <- rbind(blanks_meansLoLin, dups_LoLin) %>%  dplyr::arrange(Date_formatted, Run, pH)
# mean blanks for the start - to - end values ('Rate_mgO2_hour')
blanks_meansStartEnd <- blanks_all_raw %>%
dplyr::group_by(Date, pH, Run, filetype) %>% # grouped by date, pH, and instrument - similar among Runs
dplyr::filter(!Rate_mgO2_hour < 0) %>% # ommit blank calls that d/n represent oxygen consumption
dplyr::summarise(BLANK.start.end_mean  = mean(Rate_mgO2_hour),
# BLANK.start.end_sd  = sd(Rate_mgO2_hour),
n = n()) %>%
dplyr::mutate(Date_formatted =  gsub("-", "", substr( (strptime(Date, "%m/%d/%Y")), 1,10)) ) %>%
dplyr::arrange(Date_formatted, Run, pH)
# kable(blanks_meansStartEnd) # View - notice some of the date/runs combos do not have BOTH treatmentents represented!
dups_StartEnd          <- blanks_meansStartEnd[c(1, 16,19,28),] %>% # call the rows that do not have BOTH pH 7.5 and 8.0 represented (due to positive rates, bad data, etc)
dplyr::mutate(pH = ifelse(pH == 8.0, 7.5,  ifelse(pH == 7.5, 8.0, NA))) # do a little conditional call to call the opposite treatment dataframe..
blanks_meansStartEnd   <- rbind(blanks_meansStartEnd, dups_StartEnd) %>%  dplyr::arrange(Date_formatted, Run, pH)
blanks_means <- merge(blanks_meansLoLin, blanks_meansStartEnd) %>% dplyr::arrange(Date_formatted, Run, pH)
kable(blanks_means) # View the inserted duplicates for the other treatment on same run/date
Resp.Master <- merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0) %>% # remove values with positive O2 - should be none here, double check by removing the '!' and run partial pipeline (found 9/14/2021	pH 8	LoLigo_data	CH1)
dplyr::mutate(resp_blankStand = (abs(Lpc)) - BLANK.mean_Lpc)  %>%  # Lpc =  Lolin calculated resp (used for SMR actual rates), raw value is negative, take the absolute value and subtract from the mean blank Lpc (already abs value)
dplyr::mutate(start.end_resp_blankStand = Rate_mgO2_hour - BLANK.start.end_mean) # just start and end (simplified rate in mg O2 per hour) for O:N comparisons
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype"))
blanks_means
resp.data_merged
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0)
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0) %>% # remove values with positive O2 - should be none here, double check by removing the '!' and run partial pipeline (found 9/14/2021	pH 8	LoLigo_data	CH1)
dplyr::mutate(resp_blankStand = (abs(Lpc)) - BLANK.mean_Lpc)
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0) %>% # remove values with positive O2 - should be none here, double check by removing the '!' and run partial pipeline (found 9/14/2021	pH 8	LoLigo_data	CH1)
dplyr::mutate(resp_blankStand = (abs(Lpc)) - BLANK.mean_Lpc)  %>%  # Lpc =  Lolin calculated resp (used for SMR actual rates), raw value is negative, take the absolute value and subtract from the mean blank Lpc (already abs value)
dplyr::mutate(start.end_resp_blankStand = Rate_mgO2_hour - BLANK.start.end_mean)
resp.data_merged
merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0)
resp.data_merged
Resp.Master <- merge(resp.data_merged, blanks_means, by=c("Date", "pH", "Run", "filetype")) %>% # NOTE: this repeats for every distinct length value
dplyr::filter(!Lpc > 0) %>% # remove values with positive O2 - should be none here, double check by removing the '!' and run partial pipeline (found 9/14/2021	pH 8	LoLigo_data	CH1)
dplyr::mutate(resp_blankStand = (abs(Lpc)) - BLANK.mean_Lpc)
Resp.Master
plot(Resp.Master$start.end_resp_blankStand, Resp.Master$resp_blankStand)
Resp.Master_OM <- Resp.Master[!is.na(Resp.Master$Length_um),] %>% dplyr::filter(!resp_blankStand < 0) %>% # ommit respiration values that are positive
dplyr::mutate(volume = case_when(filetype == "LoLigo_data" & Date == '9/14/2021' ~ 2.2, # small vessels for loligo system - 22 ml vessels
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH1' ~ 68.55323, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH2' ~ 68.85583, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021')                       & Channel == 'CH3' ~ 68.87473, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH4' ~ 68.95481, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH5' ~ 68.57288, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH6' ~ 68.01878, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH7' ~ 68.54551, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('10/26/2021','2/2/2022','3/1/2022') & Channel == 'CH8' ~ 68.53297, # larger custom vessels measured individually...
filetype == "LoLigo_data" & Date %in% c('2/2/2022','3/1/2022') & Channel == 'CH3' ~ 68.87473, # larger custom vessels measured individually... # note ch3 used vessel #9 on and after 2/2/2022
filetype == "SDR_data" ~ 1.7, # 24-well plate - 1700ul
filetype == "SDR_data" & Date %in% ('8/30/2022') ~ 0.8)) %>% # 24-well plate - 80 ul
# true rates calculated using LoLinRscript
dplyr::mutate(resp_mg_L_hr   = ( (abs(resp_blankStand)) *  # currently as just mg O2 per minute
(volume/1000) * # correct Liters - mg per L per min
60) )  %>% # convert rate per minutes to rate per hour
dplyr::mutate(resp_umol_L_hr = (resp_mg_L_hr*1000) / 32) %>% #  convert mg L per hr to umol L hr- first by mg to ug (mg*1000 = ug) and then ug to umol (1 umol = 32 ug -  ug O2 div 32 ug/umol)
# simplified start end rates used to compare O:N ratios
dplyr::mutate(start.end_resp_mg_L_hr   = (start.end_resp_blankStand*(volume/1000)))  %>% # convert rate per minutes to rate per hour
dplyr::mutate(start.end_resp_umol_L_hr = (((start.end_resp_mg_L_hr) * (1000)) / 32) ) %>% #  convert mg L per hr to umol L hr- first by mg to ug (mg*1000 = ug) and then ug to umol (1 umol = 32 ug -  ug O2 div 32 ug/umol)
dplyr::mutate(Age = case_when(Date == '9/14/2021' ~ 50, Date == '9/30/2021' ~ 66, Date == '10/26/2021' ~ 92, Date == '2/2/2022' ~ 190, Date == '3/1/2022' ~ 217)) %>%
dplyr::mutate(Fed_Unfed = case_when(Fed_Unfed == 'F' ~ "High food", is.na(Fed_Unfed) ~ "High food", Fed_Unfed == 'U' ~ "Low food")) %>%
dplyr::mutate(pCO2 = case_when(pH == 8.0 ~ "500 μatm", pH == 7.5 ~ "800 μatm"))
resp.ref
library(devtools) # devtools::install_github # use devtools to instlal github link
library(LoLinR) # install_github('colin-olito/LoLinR') # install LoLinR from github
library(dplyr)
library(lubridate)
library(rMR)
library(stringr)
setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis")
setwd("C:/Users/samuel.gurr/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis") # Work computer
path.p    <- "Data/Respiration" #the location of all your respirometry files
a         <- 0.4
ouputNAME <- "Output/Respiration/Cumulative_resp_alpha0.4_15sectrunc1hour.csv"
# call the subfolder names for the outside loop 'i' (i.e. 20210914)
folder.names           <- basename(list.files(path = path.p, pattern = "202", recursive = FALSE)) #list all csv file names in the folder and subfolders
folder.names.table     <- data.frame(folder.names)
# Call the cumulative dataframe that we will write to in the for loop below
df_total             <- data.frame() # start dataframe
resp.table           <- data.frame(matrix(nrow = 1, ncol = 7)) # create dataframe to save cumunalitively during for loop
colnames(resp.table) <- c('Date', 'Channel', 'Lpc', 'Leq' , 'Lz', 'alpha','Filename') # names for comuns in the for loop
# outside 'i' loop - call each subfolder one at a time for analysis
for(i in 11:nrow(folder.names.table)) { # for every subfolder 'i' ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# NOTE: when calling the raw files we need to accommodate the different formats
# 20210914 used the 8-channel loligo system with raw output as .txt files with 'raw' in the title - call these using dplyr in the if/else below
# 20210930 used the 24-channel SDR sensor dish with raw output as .csv files - call these in the if/else statement below
# call all txt files labeled 'raw' in each subfolder (i.e. 20210914) and create a table
if (folder.names.table[i,] %in% c('20210930','20220420', '20220422','20220824', '20220829', '20220830')) { # call data when ONLY the 24-channel SDR dish data was used (csv file output)
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "csv$", recursive = TRUE))))
} else if (folder.names.table[i,] %in% c('20211026', '20220922')) { # for day(s)s when BOTH the loligo system (txt files) AND SDR dish (csv files) were used
file.names.table1    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
file.names.table2    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "csv$", recursive = TRUE)))) #%>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
file.names.table     <- rbind(file.names.table1, file.names.table2)
}  else { # all other data that used ONLY the  8-channel loligo system outputting .txt raw files (now 9/14/21 and 2/2/22)
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
}
# inside 'm' loop - call each  raw .txt or raw .csv file file witin the subfolder 'i'
for(m in 1:nrow(file.names.table)) { # for every raw .txt or csv file 'm' in the subfolder 'i' :::::::::::::::::::::::::::::::::::::
if (gsub(".*_raw.","", file.names.table[m,]) == "txt") { # call .txt 8-channel LoLigo data
Resp.Data <- read.delim2(file = paste(path.p,'/',folder.names.table[i,1], '/', file.names.table[m,1], sep=''), header = TRUE,skip = 37, fileEncoding= "windows-1252") #reads in the data files
# for data in 2021 and data in 2022
if (str_split((Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.[1]), "/", simplify = TRUE)[[3]] == "2021") {
Resp.Data$date      <- paste((sub("2021.*", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.)), '2021', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2021/", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
} else {
Resp.Data$date      <- paste((sub("2022.*", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.)), '2022', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2022/", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
}
Resp.Data$seconds   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])    # secs - calc the sec time series
Resp.Data$minutes   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])/60 # mins - calc the minute time series
temperature_C       <- as.numeric(Resp.Data$CH1.temp...C.[1])
barromP_kPa         <- as.numeric(Resp.Data$Barometric.pressure..hPa.[1]) / 10
salinity.pp.thou    <- as.numeric(Resp.Data$Salinity....[1])
Resp.Data           <- Resp.Data %>% # use 'dplyr'
dplyr::select(c(date, seconds, minutes, contains(".O2...air.sat"))) # %>%  # call unique column names for the 8 Channels
# rename columns
colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] <- substr( ( colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] ), 1,3) # clean these column names to make things easier - first 3 characters
# Truncate! EVERY 15 SECONDS (note: these txt files are long with measurements every second,trancating reduces the analysis time dramatically)
# the loligo recorded values every second, this slows the model dramatically with >2000 values for each Channel, call every 15 seconds to speed this up
Resp.Data_15sec = Resp.Data[seq(1, nrow(Resp.Data), 15), ] # truncate every 15 seconds
} else { # call .csv Presens SensorDish data
Resp.Data           <- read.csv(file = paste(path.p,'/',folder.names.table[i,1], '/', file.names.table[m,1], sep=''), header = TRUE,skip = 51) #reads in the data files
# reformat data in 2021 and data in 2022
if (str_split((Resp.Data$Date..DD.MM.YYYY.[1]), "/", simplify = TRUE)[[3]] == "2021") {
Resp.Data$date      <- paste((sub("2021.*", "", Resp.Data$Date..DD.MM.YYYY.)), '2021', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2021/", "", Resp.Data$Time..HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
} else {
Resp.Data$date      <- paste((sub("2022.*", "", Resp.Data$Date..DD.MM.YYYY.)), '2022', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2022/", "", Resp.Data$Time..HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
}
Resp.Data$seconds   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])    # secs - calc the sec time series
Resp.Data$minutes   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])/60 # mins - calc the minute time series
temperature_C       <- as.numeric(Resp.Data$CH1.temp...C.[1])
barromP_kPa         <- as.numeric(Resp.Data$Barometric.pressure..hPa.[1]) / 10
salinity.pp.thou    <- as.numeric(Resp.Data$Salinity....[1])
Resp.Data           <- Resp.Data %>% # use 'dplyr'
dplyr::select(c(date, seconds, minutes, contains("..Oxygen."))) # call unique column names for the 24 channels
colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] <- substr( ( colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] ), 1,2)
Resp.Data_15sec     <- Resp.Data # No need to truncate! The SDR SensorDish data is already recoreded every 15 seconds. simply rename for consistancy with the .txt LoLigo call
} # clean these column names to make things easier - first 3 characters
if (folder.names.table[i,] == '20210930'){
Resp.Data_15sec = Resp.Data_15sec  %>%  dplyr::filter(minutes < 40) # SDR data is already taken every 15 seconds, truncate for < 40 minutes in runs as the records start to show noise and undesirable data for O2 consumption (ran whole record and observed ALL Lolin plots to make this decision)
} else if (folder.names.table[i,] == '20220830' & substr(file.names.table[m,], 5,7) == '799'){
Resp.Data_15sec = Resp.Data_15sec  %>%  dplyr::filter(minutes >25 & minutes < 120) # plate 1 SDR 799 for 8/30/22 data, ran for ~200 minutes with a dropoff below 5-6 mgL after 120-150 minutes (omit due to hypocia) and noise as the start ( omit before 25 minutes)
} else if (folder.names.table[i,] == '20220830' & substr(file.names.table[m,], 5,7) == '873'){
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes >15)  # 60 minute file and all data is very stable, a bit of noise initialy and omitted here
} else if (folder.names.table[i,] == '20220922' & (gsub(".*_raw.","", file.names.table[m,]) == "txt")) { # call all runs with the LoLigo system on 20220922
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 20 & minutes < 50) # call between miutes 20 and 50 of the trials - took time to start in order to close chambers and channels stopped once below defined threshold (80 % a.s.)
} else if (folder.names.table[i,] == '20220922' & (gsub(".*\\.","", file.names.table[m,]) == "csv")) { # call all runs with the SDR SensorDish system on 20220922 (.csv files)
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 10) # call data after 10 minutes
} else { # note this should only call the txt files in 20211026 as there are no .csv files in 20210914
# Resp.Data_15sec = Resp.Data %>%  dplyr::filter(minutes > 30 & minutes < 90)# for now we will run the whole dataset to see...
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 30 & minutes < 90)# for now we will run the whole dataset to see...
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 60)# 20200829 larve data, omit the linital and target the remaining
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 60)# 20200829 larve data, omit the linital and target the remaining
}
# clean these column names to make things easier - first 3 characters
# inside 'j' loop - for each 'raw' txt file 'm', call each O2 sensor/resp chamber 'j' for analysis
for(j in 4:(ncol(Resp.Data_15sec))){ # for each sensor column 'j' (..starting at column 4) :::::::::::::::::::::::::::::::
Resp_loop    <- (Resp.Data_15sec[,c(3,j)]) %>%
dplyr::filter(!str_detect(((Resp.Data_15sec[,c(3,j)])[,2]),"NaN")) %>%  # noticed some random rows have 'NaN' - so I will loop the min and Channels to omit Nas before proceeding
dplyr::mutate(minutes = as.numeric(minutes)) #  %>% # convert minutes to numeric
# dplyr::filter(minutes > max(minutes) -60) # call the ___ minutes before the end of the trial (avoid the first data points noisy and due to handling stress no resp rate)
# Loligo system needs to cnvert %air sat to mg / L whereas SDR dish does not
if ( (substr(colnames(Resp.Data_15sec)[j],1,2) == 'CH') ) { # loligo measurements need to be converted to mg/L from %air sat - these columns are written as "CH#"
Resp_loop <- Resp_loop %>%  dplyr::filter(!colnames(Resp_loop)[2] %in% 'NaN') # Lolin recorede NAs are written as 'Nan' - wonts run unless removed!
Resp_loop$mgL     <- DO.unit.convert(as.numeric(Resp_loop[,2]),  # DO in percent air sat to be converted to mgL - uses an R package from loligo rMR
DO.units.in = "pct", DO.units.out ="mg/L",
bar.units.in = "kPa", bar.press = barromP_kPa, bar.units.out = "kpa",
temp.C = temperature_C,
salinity.units = "pp.thou", salinity = salinity.pp.thou)
} else { Resp_loop$mgL <- na.omit(Resp.Data_15sec[j])
Resp_loop$mgL <- as.numeric(unlist(Resp_loop$mgL)) # need to unlist and call as numeric to run LoLinR
Resp_loop$minutes <- as.numeric(unlist(Resp_loop$minutes)) # need to unlist and call as numeric to run LoLinR
Resp_loop %>% dplyr::filter(mgL > (0.8 * max(na.omit(Resp.Data %>% select(colnames(Resp.Data_15sec[j]))))) ) # grab all data over 80% air saturation for the particular column (pre-filtered by time as 'Resp.Data')
} # for the SDR dish values that are already in mg/L simply call the column in the loop
# now run data!
if (nrow(Resp_loop) < 1) { # if column 'j' is NA write NA in the cumulative sheet...
resp.table$Date                <- Resp.Data_15sec[1,1]
resp.table$Channel             <- colnames(Resp_loop)[2]
resp.table[3:ncol(resp.table)] <- 'NA'
df       <- data.frame(resp.table) # name dataframe for this single row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
} else { # else run LoLinR for x=mins and y=mg/l O2
model <- rankLocReg(
xall    = as.numeric(Resp_loop[, 1]),
yall    = as.numeric(Resp_loop[, 3]), # call x as the minute timeseries and y as the mg L-1 O2
alpha   = a,  # alpha was assigned earlier as 0.4 by the authors default suggestions - review Olito et al. and their github page for details
method  = "pc",
verbose = TRUE)
sum.table <- summary(model)
resp.table$Date       <- Resp.Data_15sec[1,1]
resp.table$Channel    <- colnames(Resp_loop)[2]
resp.table$Lpc        <- sum.table$Lcompare[3,6] # Lpc slope - call the column 'b1'
resp.table$Leq        <- sum.table$Lcompare[2,6] # Leq slope - call the column 'b1'
resp.table$Lz         <- sum.table$Lcompare[1,6] # Lz slope  - call the column 'b1'
resp.table$alpha      <- a
resp.table$Filename   <- file.names.table[m,1]
df       <- data.frame(resp.table) # name dataframe for this single row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
}  # end of  else statement (if column 'j' is NA write NA in the cumulative sheet, else run LoLinR for x=mins and y = mg/l O2)
# save plots every inside loop and name by date_run_vialposition
if (gsub(".*_raw.","", file.names.table[m,1]) == "txt") {
pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", sub("_raw.*","",file.names.table[m,1]),"_",colnames(Resp_loop)[2],"_regression.pdf"))
#pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", sub("_raw.*","",file.names.table[m,1]),"_",colnames(Resp_loop)[2],"_regression.pdf"))
plot(model)
dev.off()
} else if (folder.names.table[i,] == '20210930') {
#pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", substr( (sub(".*M_","",file.names.table[m,1])), 1,13),"_",colnames(Resp_loop)[2],"_regression.pdf"))
pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", substr( (sub(".*M_","",file.names.table[m,1])), 1,13),"_",colnames(Resp_loop)[2],"_regression.pdf"))
plot(model)
dev.off() } else { # just for the SDR run on 20211025 .csv file
pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", substr((sub(".*resp_","",file.names.table[m,1])), 1, 6),"_",colnames(Resp_loop)[2],"_regression.pdf")) # 20211026_resp_unfed.csv ONLY
#pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", substr((sub(".*resp_","",file.names.table[m,1])), 1, 6),"_",colnames(Resp_loop)[2],"_regression.pdf")) # 20211026_resp_unfed.csv ONLY
plot(model)
dev.off()
}
} # end of inside for loop 'j' (for each sensor column 'j' [a] isolate mins and CH_ for analysis [b] convert CH_ data to mg/L using 'DO.unit.convert' [c] calc respi rates with LoLin R)
} # end of inside  for loop 'm' (for every 'raw' .txt file 'm' in the subfolder 'i')
} # end of outside for loop 'i' (for every subfolder 'i')
Resp_loop
Resp_loop[, 1]
Resp_loop[, 3]
model <- rankLocReg(
xall    = as.numeric(Resp_loop[, 1]),
yall    = as.numeric(Resp_loop[, 3]), # call x as the minute timeseries and y as the mg L-1 O2
alpha   = a,  # alpha was assigned earlier as 0.4 by the authors default suggestions - review Olito et al. and their github page for details
method  = "pc",
verbose = TRUE)
as.numeric(Resp_loop[, 1])[1:20]
model <- rankLocReg(
xall    = as.numeric(Resp_loop[, 1])[1:40],
yall    = as.numeric(Resp_loop[, 3])[1:40], # call x as the minute timeseries and y as the mg L-1 O2
alpha   = a,  # alpha was assigned earlier as 0.4 by the authors default suggestions - review Olito et al. and their github page for details
method  = "pc",
verbose = TRUE)
as.numeric(Resp_loop[, 1])
setwd("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis")
path.p    <- "Data/Respiration" #the location of all your respirometry files
a         <- 0.4
ouputNAME <- "Output/Respiration/Cumulative_resp_alpha0.4_15sectrunc1hour.csv"
# call the subfolder names for the outside loop 'i' (i.e. 20210914)
folder.names           <- basename(list.files(path = path.p, pattern = "202", recursive = FALSE)) #list all csv file names in the folder and subfolders
folder.names.table     <- data.frame(folder.names)
# Call the cumulative dataframe that we will write to in the for loop below
df_total             <- data.frame() # start dataframe
resp.table           <- data.frame(matrix(nrow = 1, ncol = 7)) # create dataframe to save cumunalitively during for loop
colnames(resp.table) <- c('Date', 'Channel', 'Lpc', 'Leq' , 'Lz', 'alpha','Filename') # names for comuns in the for loop
# outside 'i' loop - call each subfolder one at a time for analysis
for(i in 11:nrow(folder.names.table)) { # for every subfolder 'i' ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# NOTE: when calling the raw files we need to accommodate the different formats
# 20210914 used the 8-channel loligo system with raw output as .txt files with 'raw' in the title - call these using dplyr in the if/else below
# 20210930 used the 24-channel SDR sensor dish with raw output as .csv files - call these in the if/else statement below
# call all txt files labeled 'raw' in each subfolder (i.e. 20210914) and create a table
if (folder.names.table[i,] %in% c('20210930','20220420', '20220422','20220824', '20220829', '20220830')) { # call data when ONLY the 24-channel SDR dish data was used (csv file output)
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "csv$", recursive = TRUE))))
} else if (folder.names.table[i,] %in% c('20211026', '20220922')) { # for day(s)s when BOTH the loligo system (txt files) AND SDR dish (csv files) were used
file.names.table1    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
file.names.table2    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "csv$", recursive = TRUE)))) #%>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
file.names.table     <- rbind(file.names.table1, file.names.table2)
}  else { # all other data that used ONLY the  8-channel loligo system outputting .txt raw files (now 9/14/21 and 2/2/22)
file.names.table    <- data.frame(txt.files = (basename(list.files(path = paste(path.p,'/',folder.names.table[i,1],sep=''), pattern = "txt$", recursive = TRUE)))) %>%  dplyr::filter(grepl('raw', txt.files))#list all csv file names in the folder and subfolders
}
# inside 'm' loop - call each  raw .txt or raw .csv file file witin the subfolder 'i'
for(m in 1:nrow(file.names.table)) { # for every raw .txt or csv file 'm' in the subfolder 'i' :::::::::::::::::::::::::::::::::::::
if (gsub(".*_raw.","", file.names.table[m,]) == "txt") { # call .txt 8-channel LoLigo data
Resp.Data <- read.delim2(file = paste(path.p,'/',folder.names.table[i,1], '/', file.names.table[m,1], sep=''), header = TRUE,skip = 37, fileEncoding= "windows-1252") #reads in the data files
# for data in 2021 and data in 2022
if (str_split((Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.[1]), "/", simplify = TRUE)[[3]] == "2021") {
Resp.Data$date      <- paste((sub("2021.*", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.)), '2021', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2021/", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
} else {
Resp.Data$date      <- paste((sub("2022.*", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.)), '2022', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2022/", "", Resp.Data$Date..Time..DD.MM.YYYY.HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
}
Resp.Data$seconds   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])    # secs - calc the sec time series
Resp.Data$minutes   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])/60 # mins - calc the minute time series
temperature_C       <- as.numeric(Resp.Data$CH1.temp...C.[1])
barromP_kPa         <- as.numeric(Resp.Data$Barometric.pressure..hPa.[1]) / 10
salinity.pp.thou    <- as.numeric(Resp.Data$Salinity....[1])
Resp.Data           <- Resp.Data %>% # use 'dplyr'
dplyr::select(c(date, seconds, minutes, contains(".O2...air.sat"))) # %>%  # call unique column names for the 8 Channels
# rename columns
colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] <- substr( ( colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] ), 1,3) # clean these column names to make things easier - first 3 characters
# Truncate! EVERY 15 SECONDS (note: these txt files are long with measurements every second,trancating reduces the analysis time dramatically)
# the loligo recorded values every second, this slows the model dramatically with >2000 values for each Channel, call every 15 seconds to speed this up
Resp.Data_15sec = Resp.Data[seq(1, nrow(Resp.Data), 15), ] # truncate every 15 seconds
} else { # call .csv Presens SensorDish data
Resp.Data           <- read.csv(file = paste(path.p,'/',folder.names.table[i,1], '/', file.names.table[m,1], sep=''), header = TRUE,skip = 51) #reads in the data files
# reformat data in 2021 and data in 2022
if (str_split((Resp.Data$Date..DD.MM.YYYY.[1]), "/", simplify = TRUE)[[3]] == "2021") {
Resp.Data$date      <- paste((sub("2021.*", "", Resp.Data$Date..DD.MM.YYYY.)), '2021', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2021/", "", Resp.Data$Time..HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
} else {
Resp.Data$date      <- paste((sub("2022.*", "", Resp.Data$Date..DD.MM.YYYY.)), '2022', sep='') #  date - use 'sub' to call everything before 2021, add back 2021 using paste
Resp.Data$time_Sec  <- period_to_seconds(hms(substr((strptime(sub(".*2022/", "", Resp.Data$Time..HH.MM.SS.), "%I:%M:%S %p")) , 12,19))) # time - use 'sub' to call target time of the raw date time after 'year/' + strptime' convert to 24 hr clock + 'period_to_seconds' converts the hms to seconds
}
Resp.Data$seconds   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])    # secs - calc the sec time series
Resp.Data$minutes   <- (Resp.Data$time_Sec - Resp.Data$time_Sec[1])/60 # mins - calc the minute time series
temperature_C       <- as.numeric(Resp.Data$CH1.temp...C.[1])
barromP_kPa         <- as.numeric(Resp.Data$Barometric.pressure..hPa.[1]) / 10
salinity.pp.thou    <- as.numeric(Resp.Data$Salinity....[1])
Resp.Data           <- Resp.Data %>% # use 'dplyr'
dplyr::select(c(date, seconds, minutes, contains("..Oxygen."))) # call unique column names for the 24 channels
colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] <- substr( ( colnames(Resp.Data)[c(4:(ncol(Resp.Data)))] ), 1,2)
Resp.Data_15sec     <- Resp.Data # No need to truncate! The SDR SensorDish data is already recoreded every 15 seconds. simply rename for consistancy with the .txt LoLigo call
} # clean these column names to make things easier - first 3 characters
if (folder.names.table[i,] == '20210930'){
Resp.Data_15sec = Resp.Data_15sec  %>%  dplyr::filter(minutes < 40) # SDR data is already taken every 15 seconds, truncate for < 40 minutes in runs as the records start to show noise and undesirable data for O2 consumption (ran whole record and observed ALL Lolin plots to make this decision)
} else if (folder.names.table[i,] == '20220830' & substr(file.names.table[m,], 5,7) == '799'){
Resp.Data_15sec = Resp.Data_15sec  %>%  dplyr::filter(minutes >25 & minutes < 120) # plate 1 SDR 799 for 8/30/22 data, ran for ~200 minutes with a dropoff below 5-6 mgL after 120-150 minutes (omit due to hypocia) and noise as the start ( omit before 25 minutes)
} else if (folder.names.table[i,] == '20220830' & substr(file.names.table[m,], 5,7) == '873'){
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes >15)  # 60 minute file and all data is very stable, a bit of noise initialy and omitted here
} else if (folder.names.table[i,] == '20220922' & (gsub(".*_raw.","", file.names.table[m,]) == "txt")) { # call all runs with the LoLigo system on 20220922
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 20 & minutes < 50) # call between miutes 20 and 50 of the trials - took time to start in order to close chambers and channels stopped once below defined threshold (80 % a.s.)
} else if (folder.names.table[i,] == '20220922' & (gsub(".*\\.","", file.names.table[m,]) == "csv")) { # call all runs with the SDR SensorDish system on 20220922 (.csv files)
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 10 & minutes < 50) # call data after 10 minutes
} else { # note this should only call the txt files in 20211026 as there are no .csv files in 20210914
# Resp.Data_15sec = Resp.Data %>%  dplyr::filter(minutes > 30 & minutes < 90)# for now we will run the whole dataset to see...
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 30 & minutes < 90)# for now we will run the whole dataset to see...
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 60)# 20200829 larve data, omit the linital and target the remaining
Resp.Data_15sec = Resp.Data_15sec %>%  dplyr::filter(minutes > 60)# 20200829 larve data, omit the linital and target the remaining
}
# clean these column names to make things easier - first 3 characters
# inside 'j' loop - for each 'raw' txt file 'm', call each O2 sensor/resp chamber 'j' for analysis
for(j in 4:(ncol(Resp.Data_15sec))){ # for each sensor column 'j' (..starting at column 4) :::::::::::::::::::::::::::::::
Resp_loop    <- (Resp.Data_15sec[,c(3,j)]) %>%
dplyr::filter(!str_detect(((Resp.Data_15sec[,c(3,j)])[,2]),"NaN")) %>%  # noticed some random rows have 'NaN' - so I will loop the min and Channels to omit Nas before proceeding
dplyr::mutate(minutes = as.numeric(minutes)) #  %>% # convert minutes to numeric
# dplyr::filter(minutes > max(minutes) -60) # call the ___ minutes before the end of the trial (avoid the first data points noisy and due to handling stress no resp rate)
# Loligo system needs to cnvert %air sat to mg / L whereas SDR dish does not
if ( (substr(colnames(Resp.Data_15sec)[j],1,2) == 'CH') ) { # loligo measurements need to be converted to mg/L from %air sat - these columns are written as "CH#"
Resp_loop <- Resp_loop %>%  dplyr::filter(!colnames(Resp_loop)[2] %in% 'NaN') # Lolin recorede NAs are written as 'Nan' - wonts run unless removed!
Resp_loop$mgL     <- DO.unit.convert(as.numeric(Resp_loop[,2]),  # DO in percent air sat to be converted to mgL - uses an R package from loligo rMR
DO.units.in = "pct", DO.units.out ="mg/L",
bar.units.in = "kPa", bar.press = barromP_kPa, bar.units.out = "kpa",
temp.C = temperature_C,
salinity.units = "pp.thou", salinity = salinity.pp.thou)
} else { Resp_loop$mgL <- na.omit(Resp.Data_15sec[j])
Resp_loop$mgL <- as.numeric(unlist(Resp_loop$mgL)) # need to unlist and call as numeric to run LoLinR
Resp_loop$minutes <- as.numeric(unlist(Resp_loop$minutes)) # need to unlist and call as numeric to run LoLinR
Resp_loop %>% dplyr::filter(mgL > (0.8 * max(na.omit(Resp.Data %>% select(colnames(Resp.Data_15sec[j]))))) ) # grab all data over 80% air saturation for the particular column (pre-filtered by time as 'Resp.Data')
} # for the SDR dish values that are already in mg/L simply call the column in the loop
# now run data!
if (nrow(Resp_loop) < 1) { # if column 'j' is NA write NA in the cumulative sheet...
resp.table$Date                <- Resp.Data_15sec[1,1]
resp.table$Channel             <- colnames(Resp_loop)[2]
resp.table[3:ncol(resp.table)] <- 'NA'
df       <- data.frame(resp.table) # name dataframe for this single row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
} else { # else run LoLinR for x=mins and y=mg/l O2
model <- rankLocReg(
xall    = as.numeric(Resp_loop[, 1]),
yall    = as.numeric(Resp_loop[, 3]), # call x as the minute timeseries and y as the mg L-1 O2
alpha   = a,  # alpha was assigned earlier as 0.4 by the authors default suggestions - review Olito et al. and their github page for details
method  = "pc",
verbose = TRUE)
sum.table <- summary(model)
resp.table$Date       <- Resp.Data_15sec[1,1]
resp.table$Channel    <- colnames(Resp_loop)[2]
resp.table$Lpc        <- sum.table$Lcompare[3,6] # Lpc slope - call the column 'b1'
resp.table$Leq        <- sum.table$Lcompare[2,6] # Leq slope - call the column 'b1'
resp.table$Lz         <- sum.table$Lcompare[1,6] # Lz slope  - call the column 'b1'
resp.table$alpha      <- a
resp.table$Filename   <- file.names.table[m,1]
df       <- data.frame(resp.table) # name dataframe for this single row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
}  # end of  else statement (if column 'j' is NA write NA in the cumulative sheet, else run LoLinR for x=mins and y = mg/l O2)
# save plots every inside loop and name by date_run_vialposition
if (gsub(".*_raw.","", file.names.table[m,1]) == "txt") {
pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", sub("_raw.*","",file.names.table[m,1]),"_",colnames(Resp_loop)[2],"_regression.pdf"))
#pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", sub("_raw.*","",file.names.table[m,1]),"_",colnames(Resp_loop)[2],"_regression.pdf"))
plot(model)
dev.off()
} else if (folder.names.table[i,] == '20210930') {
#pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", substr( (sub(".*M_","",file.names.table[m,1])), 1,13),"_",colnames(Resp_loop)[2],"_regression.pdf"))
pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", substr( (sub(".*M_","",file.names.table[m,1])), 1,13),"_",colnames(Resp_loop)[2],"_regression.pdf"))
plot(model)
dev.off() } else { # just for the SDR run on 20211025 .csv file
pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", substr((sub(".*resp_","",file.names.table[m,1])), 1, 6),"_",colnames(Resp_loop)[2],"_regression.pdf")) # 20211026_resp_unfed.csv ONLY
#pdf(paste0("C:/Users/samjg/Documents/Github_repositories/Airradians_multigen_OA/RAnalysis/Output/Respiration/plots_alpha0.4_increm15sec/",folder.names.table[i,1],"_", substr((sub(".*resp_","",file.names.table[m,1])), 1, 6),"_",colnames(Resp_loop)[2],"_regression.pdf")) # 20211026_resp_unfed.csv ONLY
plot(model)
dev.off()
}
} # end of inside for loop 'j' (for each sensor column 'j' [a] isolate mins and CH_ for analysis [b] convert CH_ data to mg/L using 'DO.unit.convert' [c] calc respi rates with LoLin R)
} # end of inside  for loop 'm' (for every 'raw' .txt file 'm' in the subfolder 'i')
} # end of outside for loop 'i' (for every subfolder 'i')
# merge with the preexisiting table
# NOTE: raw values here are...
# (1) in units of mg/L min-1 (slope of line mg/l / mins in LoLinR - check the plot outputs to see)
# (2) not normalized for volume chamber
# (3) not normalized for blank resp rate
# (4) not normalized for a size/individual metric (i.e. Tissue Dry weight, shell length, etc.)
cumulative_resp_table <- read.csv(file=ouputNAME, header=TRUE) #call the pre existing cumulative table
cumulative_resp_table
new_table             <- rbind(cumulative_resp_table, df_total) # bind the new table from the for loop to the pre exisiting table
write.table(new_table,ouputNAME,sep=",", row.names=FALSE)  # write out to the path names outputNAME
